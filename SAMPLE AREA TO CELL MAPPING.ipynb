{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/ScMa9004/Downloads/RULES_1579101873184.csv', sep = ',', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из выгрузки правил вырезать нужные\n",
    "df = df[df['CREATED_BY'] == 'maxim.schenin@nielsen.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns = {'CELL_AREA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc = pd.read_excel('C:/Users/ScMa9004/Documents/All Russia cities 01.01.2019_ for_2020.xlsx',\n",
    "                    sheet_name = 'All_Russia_cities', skiprows = 1)\n",
    "#replase MSC to 1\n",
    "arc.loc[arc['RMS_CLUSTER_CODE (справочник)'].isin(['MSC1', 'MSC2']), 'RMS_CLUSTER_CODE (справочник)'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "uo200 = pd.read_excel('C:/Users/ScMa9004/Documents/Universe Over 200.xls', sheet_name = 'Towns&Villages', skiprows = 1)\n",
    "#drop nonaudited subjects\n",
    "uo200 = uo200[~uo200['Federal Subject Number'].isin([4, 42, 43, 44, 45, 46, 47, 48, 60, 68, 70, 71, 79, 80, 81, 85, 87, 88])]\n",
    "#replase MSC to 1\n",
    "uo200.loc[uo200['RMS_CLUSTER_CODE (ACR)'].isin(['MSC1', 'MSC2']), 'RMS_CLUSTER_CODE (ACR)'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_excel('C:/Users/ScMa9004/Documents/Panel/NEW PANEL/FMCG_CIG_BEER.xlsx', \n",
    "                                  sheet_name = 'index + mcellname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(mcell):\n",
    "    if mcell.split('-')[0] in ['CNT', 'FST', 'VOL', 'URL', 'NWT', 'STH', 'MSO', 'SIB']:\n",
    "        area = [mcell.split('-')[0]]\n",
    "        if 'RR' in mcell.split('-')[-1]:\n",
    "            ccodes = []\n",
    "            subreg = list(map(int, mcell.split('-')[1].split('|')))\n",
    "            types = ['OSU|OLA|OME|OSM|OPV|OMM|OMS']\n",
    "            pgr = list(mcell.split('-')[2].split('|'))\n",
    "            ds = list(mcell.split('-')[3].split('|'))\n",
    "            hip = []\n",
    "            ndx = [mcell.split('-')[-1]]\n",
    "            NO_city = []\n",
    "            ttr = ['MT|TT']\n",
    "        else:\n",
    "            ccodes = []\n",
    "            subreg = list(map(int, mcell.split('-')[1].split('|')))\n",
    "            if ('IML' in mcell.split('-')[2]) | ('IMS' in mcell.split('-')[2]):\n",
    "                types = ['OKS', 'ONS', 'OPV', 'OSM']\n",
    "            else:\n",
    "                types = list(mcell.split('-')[2].split('|'))\n",
    "            pgr = list(map(int, mcell.split('-')[3].split('|')))\n",
    "            ttr = list(mcell.split('-')[4].split('|'))\n",
    "            try:\n",
    "                NO_city = list(map(int, mcell.split('-')[5].replace('(', '').replace(')', '').split('&')))\n",
    "            except:\n",
    "                NO_city = []\n",
    "            hip = []\n",
    "            ndx = [mcell.split('-')[-1]]\n",
    "            ds = []\n",
    "    else:\n",
    "        if '|' in mcell.split('-')[0]:\n",
    "            area = [mcell.split('-')[0] + ' ' + mcell.split('-')[1]]\n",
    "        else:\n",
    "            area = [mcell.split('-')[1]]\n",
    "        ccodes = list(map(int, mcell.split('-')[0].split('|')))\n",
    "        subreg = []\n",
    "        types = list(mcell.split('-')[2].split('|'))\n",
    "        if ('Y' in mcell.split('-')[3]) | ('N' in mcell.split('-')[3]):\n",
    "            ttr = ['TT']\n",
    "            hip = list(mcell.split('-')[3])\n",
    "        else:\n",
    "            ttr = list(mcell.split('-')[3].split('|'))\n",
    "            hip = []\n",
    "        NO_city = []\n",
    "        pgr = []\n",
    "        ndx = [mcell.split('-')[-1]]\n",
    "        ds = []\n",
    "    return(area, ccodes, subreg, types, pgr, ttr, NO_city, hip, ds, ndx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL_AREA MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df['RULE_ID'][df['RULE_TYPE'] == 'MICRO_CELL'].unique():\n",
    "    try:\n",
    "        a = df['RULE_ID'][(df['RULE_TYPE'] == 'CELL_AREA') &\n",
    "            (df['ATTRIBUTE_ID'] == 1001023) &\n",
    "              (df['VALUE'] == df['VALUE'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 1001023)].iloc[0]) &\n",
    "              (df['OPERATOR'] == df['OPERATOR'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 1001023)].iloc[0])]\n",
    "    except:\n",
    "        a = df['RULE_ID'][df['RULE_TYPE'] == 'CELL_AREA'].unique()\n",
    "    try:\n",
    "        b = df['RULE_ID'][(df['RULE_TYPE'] == 'CELL_AREA') &\n",
    "                    (df['ATTRIBUTE_ID'] == 1001022) &      \n",
    "              (df['VALUE'] == df['VALUE'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 1001022)].iloc[0]) &\n",
    "              (df['OPERATOR'] == df['OPERATOR'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 1001022)].iloc[0])]\n",
    "    except:\n",
    "        b = df['RULE_ID'][df['RULE_TYPE'] == 'CELL_AREA'].unique()\n",
    "    try:\n",
    "        c = df['RULE_ID'][(df['RULE_TYPE'] == 'CELL_AREA') &\n",
    "                        (df['ATTRIBUTE_ID'] == 20125) &  \n",
    "              (df['VALUE'] == df['VALUE'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 20125)].iloc[0]) &\n",
    "              (df['OPERATOR'] == df['OPERATOR'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 20125)].iloc[0])]\n",
    "    except:\n",
    "        c = df['RULE_ID'][df['RULE_TYPE'] == 'CELL_AREA'].unique()\n",
    "    try:\n",
    "        d = df['RULE_ID'][(df['RULE_TYPE'] == 'CELL_AREA') &\n",
    "                          (df['ATTRIBUTE_ID'] == 21118) &\n",
    "              (df['VALUE'] == df['VALUE'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 21118)].iloc[0]) &\n",
    "              (df['OPERATOR'] == df['OPERATOR'][(df['RULE_ID'] == i) & (df['ATTRIBUTE_ID'] == 21118)].iloc[0])]\n",
    "    except:\n",
    "        d = df['RULE_ID'][df['RULE_TYPE'] == 'CELL_AREA'].unique()\n",
    "        \n",
    "    e = set(a) & set(b) & set(c) & set(d)\n",
    "    \n",
    "    res.loc[i, 'CELL_AREA'] = e\n",
    "    \n",
    "res = res.reset_index(drop = False)\n",
    "    \n",
    "res['CELL_AREA'] = res['CELL_AREA'].astype('str')\n",
    "    \n",
    "res['CELL_AREA'] = res['CELL_AREA'].str.replace('{', '')\n",
    "res['CELL_AREA'] = res['CELL_AREA'].str.replace('}', '')\n",
    "\n",
    "for i, j in res.iterrows():\n",
    "    if len(j['CELL_AREA'].split(',')) > 1:\n",
    "        if len(df[df['RULE_ID'] == int(j['CELL_AREA'].split(',')[0])]) ==\\\n",
    "        len(df[(df['RULE_ID'] == j['index']) &\\\n",
    "                (df['ATTRIBUTE_NAME'].isin(df['ATTRIBUTE_NAME'][df['RULE_ID'] == int(j['CELL_AREA'].split(',')[0])]))]):\n",
    "            res.loc[i, 'CELL_AREA'] = int(j['CELL_AREA'].split(',')[0])\n",
    "        else:\n",
    "            res.loc[i, 'CELL_AREA'] = int(j['CELL_AREA'].split(',')[1])\n",
    "            \n",
    "res = res.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = pd.merge(res.rename(columns = {'index': 'RULE_ID'}), df[['RULE_ID', 'RULE_NAME']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['ndx'] = np.nan\n",
    "\n",
    "for i, j in res.iterrows():\n",
    "    res.loc[i, 'ndx'] = j['RULE_NAME'].split('-')[-1]\n",
    "\n",
    "res.loc[res['ndx'] == 'FMCG', 'INDEX_ID'] = 1000296\n",
    "res.loc[(res['ndx'] == 'CIG') | (res['ndx'] == 'RRC'), 'INDEX_ID'] = 1000334\n",
    "res.loc[(res['ndx'] == 'BEER') | (res['ndx'] == 'RRB'), 'INDEX_ID'] = 1000328\n",
    "res.loc[res['ndx'] == 'EXXON', 'INDEX_ID'] = 1001395\n",
    "\n",
    "res.loc[res['ndx'] == 'FMCG', 'INDEX_NAME'] = 'RU FMCG AUDIT - DUPLICATE'\n",
    "res.loc[(res['ndx'] == 'CIG') | (res['ndx'] == 'RRC'), 'INDEX_NAME'] = 'RU CIG AUDIT - DUPLICATE'\n",
    "res.loc[(res['ndx'] == 'BEER') | (res['ndx'] == 'RRB'), 'INDEX_NAME'] = 'RU BEER AUDIT - DUPLICATE'\n",
    "res.loc[res['ndx'] == 'EXXON', 'INDEX_NAME'] = 'RU EXXON AUDIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URBAN split by cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_2(mcell):\n",
    "    if mcell.split('-')[0] in ['CNT', 'FST', 'VOL', 'URL', 'NWT', 'STH', 'MSO', 'SIB']:\n",
    "        area = [mcell.split('-')[0]]\n",
    "        if 'RR' in mcell.split('-')[-1]:\n",
    "            ccodes = []\n",
    "            subreg = list(map(int, mcell.split('-')[1].split('|')))\n",
    "            types = ['OSU|OLA|OME|OSM|OPV|OMM|OMS']\n",
    "            pgr = list(mcell.split('-')[2].split('|'))\n",
    "            ds = list(mcell.split('-')[3].split('|'))\n",
    "            hip = []\n",
    "            ndx = [mcell.split('-')[-1]]\n",
    "            NO_city = []\n",
    "            ttr = ['MT|TT']\n",
    "        else:\n",
    "            ccodes = []\n",
    "            subreg = list(map(int, mcell.split('-')[1].split('|')))\n",
    "            #if ('IML' in mcell.split('-')[2]) | ('IMS' in mcell.split('-')[2]):\n",
    "            #    types = ['OKS', 'ONS', 'OPV', 'OSM']\n",
    "            #else:\n",
    "            types = list(mcell.split('-')[2].split('|'))\n",
    "            pgr = list(map(int, mcell.split('-')[3].split('|')))\n",
    "            ttr = list(mcell.split('-')[4].split('|'))\n",
    "            try:\n",
    "                NO_city = list(map(int, mcell.split('-')[5].replace('(', '').replace(')', '').split('&')))\n",
    "            except:\n",
    "                NO_city = []\n",
    "            hip = []\n",
    "            ndx = [mcell.split('-')[-1]]\n",
    "            ds = []\n",
    "    else:\n",
    "        if '|' in mcell.split('-')[0]:\n",
    "            area = [mcell.split('-')[0] + ' ' + mcell.split('-')[1]]\n",
    "        else:\n",
    "            area = [mcell.split('-')[1]]\n",
    "        ccodes = list(map(int, mcell.split('-')[0].split('|')))\n",
    "        subreg = []\n",
    "        types = list(mcell.split('-')[2].split('|'))\n",
    "        if ('Y' in mcell.split('-')[3]) | ('N' in mcell.split('-')[3]):\n",
    "            ttr = ['TT']\n",
    "            hip = list(mcell.split('-')[3])\n",
    "        else:\n",
    "            ttr = list(mcell.split('-')[3].split('|'))\n",
    "            hip = []\n",
    "        NO_city = []\n",
    "        pgr = []\n",
    "        ndx = [mcell.split('-')[-1]]\n",
    "        ds = []\n",
    "    return(area, ccodes, subreg, types, pgr, ttr, NO_city, hip, ds, ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare file\n",
    "def urban_syndi(df, arc):\n",
    "    \n",
    "    # some types should stay together\n",
    "    for i, j in df.iterrows():\n",
    "        df.loc[i, 'new_mcell_name'] = df['new_mcell_name'][i].replace('FKF|FKT|FKM|FKC', 'FKF/FKT/FKM/FKC')\n",
    "    \n",
    "    \n",
    "    res = pd.DataFrame(columns = {'city', 'FMCG', 'CIG', 'BEER', 'EXXON', 'type', 'ttr', 'MCELL_ID'})\n",
    "    \n",
    "    n = 0\n",
    "    for i, j in df[df['index'] < 10000].iterrows():\n",
    "        wrk = parser_2(j['new_mcell_name'])\n",
    "        if len(wrk[1]) > 0:\n",
    "            cities = wrk[1]\n",
    "        else:\n",
    "            cities = arc['City Code'][arc['# of Federal Subject'].isin(wrk[2]) & \n",
    "                                      arc['pgr1'].isin(wrk[4]) & \n",
    "                                      ~arc['City Code'].isin(wrk[6]) &\n",
    "                                      arc['City Code'].notna() &\n",
    "                                      arc['Restrict for audit '].isin([0])]\n",
    "        for k in cities:\n",
    "            for l in wrk[3]:\n",
    "                for m in wrk[5]:\n",
    "                    res.loc[n, 'city'] = k\n",
    "                    res.loc[n, 'type'] = l\n",
    "                    res.loc[n, 'ttr'] = m\n",
    "                    if 'FMCG' in wrk[9]:\n",
    "                        res.loc[n, 'FMCG'] = df['MCELL_ID'][i]\n",
    "                    if 'CIG' in wrk[9]:\n",
    "                        res.loc[n, 'CIG'] = df['MCELL_ID'][i]\n",
    "                    if 'BEER' in wrk[9]:\n",
    "                        res.loc[n, 'BEER'] = df['MCELL_ID'][i]\n",
    "                    if 'EXXON' in wrk[9]:\n",
    "                        res.loc[n, 'EXXON'] = df['MCELL_ID'][i]\n",
    "                    n += 1 \n",
    "    \n",
    "    res = res.fillna(0)\n",
    "    \n",
    "    res = pd.merge(res, \n",
    "                   arc[['City Code', 'RMS_CLUSTER_CODE (справочник)']].rename(columns =\\\n",
    "                                                {'City Code': 'city', 'RMS_CLUSTER_CODE (справочник)': 'ops'}).dropna(), \n",
    "                   on = 'city', \n",
    "                   how = 'left')\n",
    "    \n",
    "    pivot = pd.pivot_table(res, \n",
    "                           index = ['ops', 'city', 'type', 'ttr'], \n",
    "                           values = ['FMCG', 'CIG', 'BEER', 'EXXON'], \n",
    "                           aggfunc = np.sum).reset_index()\n",
    "    \n",
    "    pivot['city'] = pivot['city'].astype('int')\n",
    "    \n",
    "    pivot = pd.pivot_table(pivot, \n",
    "                           index = ['ops', 'type', 'ttr', 'FMCG', 'CIG', 'BEER', 'EXXON'], \n",
    "                           values = ['city'], \n",
    "                           aggfunc = lambda x: list(x.unique())).reset_index()\n",
    "    \n",
    "    pivot['city'] = pivot['city'].astype('str')\n",
    "    \n",
    "    pivot = pd.pivot_table(pivot,\n",
    "               index = ['ops', 'ttr', 'FMCG', 'CIG', 'BEER', 'EXXON', 'city'], \n",
    "               values = 'type', \n",
    "               aggfunc = lambda x: list(x.unique())).reset_index()\n",
    "    \n",
    "    pivot['type'] = pivot['type'].astype('str')\n",
    "    \n",
    "    pivot = pd.pivot_table(pivot,\n",
    "               index = ['ops', 'type', 'FMCG', 'CIG', 'BEER', 'EXXON', 'city'], \n",
    "               values = 'ttr', \n",
    "               aggfunc = lambda x: list(x.unique())).reset_index()\n",
    "    \n",
    "    pivot['ttr'] = pivot['ttr'].astype('str')\n",
    "    \n",
    "    pivot.loc[pivot['ops'] == 'MSC2', 'ops'] = 1\n",
    "    \n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = urban_syndi(rules, arc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RURAL syndicated split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_1(mcell):\n",
    "    if mcell.split('-')[0] in ['CNT', 'FST', 'VOL', 'URL', 'NWT', 'STH', 'MSO', 'SIB']:\n",
    "        area = [mcell.split('-')[0]]\n",
    "        if 'RR' in mcell.split('-')[-1]:\n",
    "            ccodes = []\n",
    "            subreg = list(map(int, mcell.split('-')[1].split('|')))\n",
    "            types = ['OSU', 'OLA', 'OME', 'OSM', 'OPV', 'OMM', 'OMS']\n",
    "            pgr = list(mcell.split('-')[2].split('|'))\n",
    "            ds = list(mcell.split('-')[3].split('|'))\n",
    "            hip = []\n",
    "            ndx = [mcell.split('-')[-1]]\n",
    "            NO_city = []\n",
    "            ttr = ['MT|TT']\n",
    "        else:\n",
    "            ccodes = []\n",
    "            subreg = list(map(int, mcell.split('-')[1].split('|')))\n",
    "            #if ('IML' in mcell.split('-')[2]) | ('IMS' in mcell.split('-')[2]):\n",
    "            #    types = ['OKS', 'ONS', 'OPV', 'OSM']\n",
    "            #    hip = [mcell.split('-')[2]]\n",
    "            #else:\n",
    "            #next 2 rows\n",
    "            types = list(mcell.split('-')[2].split('|'))\n",
    "            hip = []\n",
    "            pgr = list(map(int, mcell.split('-')[3].split('|')))\n",
    "            ttr = list(mcell.split('-')[4].split('|'))\n",
    "            try:\n",
    "                NO_city = list(map(int, mcell.split('-')[5].replace('(', '').replace(')', '').split('&')))\n",
    "            except:\n",
    "                NO_city = []\n",
    "            ndx = [mcell.split('-')[-1]]\n",
    "            ds = []\n",
    "    else:\n",
    "        if '|' in mcell.split('-')[0]:\n",
    "            area = [mcell.split('-')[0] + ' ' + mcell.split('-')[1]]\n",
    "        else:\n",
    "            area = [mcell.split('-')[1]]\n",
    "        ccodes = list(map(int, mcell.split('-')[0].split('|')))\n",
    "        subreg = []\n",
    "        hip = []\n",
    "        #if ('IML' in mcell.split('-')[2]) | ('IMS' in mcell.split('-')[2]):\n",
    "        #    types = ['OKS', 'ONS', 'OPV', 'OSM']\n",
    "        #    hip = [mcell.split('-')[2]]\n",
    "        #else:\n",
    "        types = list(mcell.split('-')[2].split('|'))\n",
    "        if ('Y' in mcell.split('-')[3]) | ('N' in mcell.split('-')[3]):\n",
    "            ttr = ['TT']\n",
    "            hip = list(mcell.split('-')[3])\n",
    "        else:\n",
    "            ttr = list(mcell.split('-')[3].split('|'))\n",
    "        NO_city = []\n",
    "        pgr = []\n",
    "        ndx = [mcell.split('-')[-1]]\n",
    "        ds = []\n",
    "    return(area, ccodes, subreg, types, pgr, ttr, NO_city, hip, ds, ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare file\n",
    "def rural_syndi(df):\n",
    "    \n",
    "    res = pd.DataFrame(columns = {'sub', 'RRC', 'RRB', 'pgr', 'DS', 'MCELL_ID'})\n",
    "    \n",
    "    #split\n",
    "    n = 0\n",
    "    for i, j in df[df['index'] >= 10000].iterrows():\n",
    "        wrk = parser_1(j['new_mcell_name'])\n",
    "        for k in wrk[2]:\n",
    "            for l in wrk[4]:\n",
    "                for m in wrk[8]:\n",
    "                    res.loc[n, 'sub'] = k\n",
    "                    res.loc[n, 'pgr'] = l\n",
    "                    res.loc[n, 'DS'] = m\n",
    "                    res.loc[n, 'MCELL_ID'] = df['MCELL_ID'][i]\n",
    "                    if 'RRC' in wrk[9]:\n",
    "                        res.loc[n, 'RRC'] = j['index']\n",
    "                    if 'RRB' in wrk[9]:\n",
    "                        res.loc[n, 'RRB'] = j['index']\n",
    "                    n += 1 \n",
    "                    \n",
    "    #syndi\n",
    "    for i, j in res[res['RRC'].notna()].iterrows():\n",
    "        try:\n",
    "            res.loc[i, 'RRB'] = res['MCELL_ID'][(res['pgr'] == j['pgr']) &\n",
    "                                           (res['DS'] == j['DS']) &\n",
    "                                           (res['sub'] == j['sub']) & res.RRB.notna()].iloc[0]\n",
    "            \n",
    "            res = res.drop([res[(res['pgr'] == j['pgr']) &\n",
    "                                (res['DS'] == j['DS']) &\n",
    "                                (res['sub'] == j['sub']) & \n",
    "                                res.RRB.notna() & \n",
    "                                res.RRC.isna()].index.item()])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #szhatie\n",
    "    res = res.fillna(0)\n",
    "    res['sub'] = res['sub'].astype('str')\n",
    "    res = pd.pivot_table(res, \n",
    "                         index = ['RRC', 'RRB'],\n",
    "                         values = ['sub', 'pgr', 'DS', 'MCELL_ID'], \n",
    "                         aggfunc = lambda x: x.unique()).reset_index()\n",
    "    \n",
    "    #replace remains of indexes on mcell ids\n",
    "    res.loc[(res['RRC'] != 0) & (res['RRB'] != 0), 'RRC'] = res['MCELL_ID']\n",
    "    res.loc[res['RRC'] == 0, 'RRB'] = res['MCELL_ID']\n",
    "    res.loc[res['RRB'] == 0, 'RRC'] = res['MCELL_ID']\n",
    "    \n",
    "    res = res.drop(columns = 'MCELL_ID')\n",
    "     \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rrl = rural_syndi(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate RRL\n",
    "rural = res[res['ndx'].isin(['RRB', 'RRC'])]\n",
    "urban = res[~res['ndx'].isin(['RRB', 'RRC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# urban\n",
    "fmcg = pivot.rename(columns = {'FMCG' : 'RULE_ID'}).drop(columns = {'CIG', 'BEER', 'EXXON'})\n",
    "cig = pivot.rename(columns = {'CIG' : 'RULE_ID'}).drop(columns = {'FMCG', 'BEER', 'EXXON'})\n",
    "beer = pivot.rename(columns = {'BEER' : 'RULE_ID'}).drop(columns = {'CIG', 'FMCG', 'EXXON'})\n",
    "exxon = pivot.rename(columns = {'EXXON' : 'RULE_ID'}).drop(columns = {'CIG', 'BEER', 'FMCG'})\n",
    "\n",
    "urbn = fmcg.append(cig).append(beer).append(exxon)\n",
    "\n",
    "urbn = urbn[urbn.RULE_ID != 0]\n",
    "\n",
    "urbn = urbn.reset_index(drop = True)\n",
    "\n",
    "urbn = pd.merge(urbn, urban, on = 'RULE_ID', how = 'left').dropna()\n",
    "\n",
    "urbn['type'] = urbn['type'].str.replace(']', '')\n",
    "urbn['type'] = urbn['type'].str.replace('[', '')\n",
    "urbn['type'] = urbn['type'].str.replace(', ', '|')\n",
    "urbn['type'] = urbn['type'].str.replace(\"'\", \"\")\n",
    "\n",
    "urbn['ttr'] = urbn['ttr'].str.replace(']', '')\n",
    "urbn['ttr'] = urbn['ttr'].str.replace('[', '')\n",
    "urbn['ttr'] = urbn['ttr'].str.replace(', ', '|')\n",
    "urbn['ttr'] = urbn['ttr'].str.replace(\"'\", \"\")\n",
    "\n",
    "urbn['city'] = urbn['city'].str.replace(']', '')\n",
    "urbn['city'] = urbn['city'].str.replace('[', '')\n",
    "urbn['city'] = urbn['city'].str.replace(', ', '|')\n",
    "urbn['city'] = urbn['city'].str.replace(\"'\", \"\")\n",
    "\n",
    "\n",
    "urbn['SAMPLE_AREA_NAME'] = urbn['ops'].astype('int').astype('str') + ' ' + urbn['type'] + '-' + urbn['ttr'] + '-' + urbn['city']\n",
    "urbn['REGION_NAME'] = urbn['SAMPLE_AREA_NAME']\n",
    "\n",
    "\n",
    "#k = 0\n",
    "#for i in urbn['REGION_NAME'].unique():\n",
    "#    k += 1\n",
    "#    urbn.loc[urbn['REGION_NAME'] == i, 'REGION_ID'] = k\n",
    "    \n",
    "#k = 0\n",
    "#for i in urbn['SAMPLE_AREA_NAME'].unique():\n",
    "#    k += 1\n",
    "#    urbn.loc[urbn['SAMPLE_AREA_NAME'] == i, 'SAMPLE_AREA_ID'] = k\n",
    "    \n",
    "urbn['REGION_ID'] = 0\n",
    "urbn['SAMPLE_AREA_ID'] = 0\n",
    "    \n",
    "urbn = urbn[['INDEX_ID', 'INDEX_NAME', 'REGION_ID', 'REGION_NAME', 'SAMPLE_AREA_ID',\n",
    "           'SAMPLE_AREA_NAME', 'CELL_AREA', 'RULE_ID']].rename(columns = {'CELL_AREA': 'CELL_AREA_RULE_ID',\n",
    "                                                                          'RULE_ID': 'MICRO_CELL_RULE_ID'})\n",
    "\n",
    "urbn['EXCLUDE_FLAG'] = 'N'\n",
    "urbn['EXCLUSION_REASON'] = 'N'\n",
    "\n",
    "urbn['INDEX_ID'] = urbn['INDEX_ID'].astype('int')\n",
    "urbn['REGION_ID'] = urbn['REGION_ID'].astype('int')\n",
    "urbn['SAMPLE_AREA_ID'] = urbn['SAMPLE_AREA_ID'].astype('int')\n",
    "urbn['CELL_AREA_RULE_ID'] = urbn['CELL_AREA_RULE_ID'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rural\n",
    "rrc = rrl\n",
    "rrb = rrl\n",
    "\n",
    "rrc = rrc.rename(columns = {'RRC': 'RULE_ID'}).drop(columns = 'RRB')\n",
    "rrb = rrb.rename(columns = {'RRB': 'RULE_ID'}).drop(columns = 'RRC')\n",
    "\n",
    "rrl = rrc.append(rrb)\n",
    "\n",
    "rrl = rrl[rrl.RULE_ID != 0]\n",
    "\n",
    "rrl = rrl.reset_index(drop = True)\n",
    "\n",
    "rrl = pd.merge(rrl, rural, on = 'RULE_ID', how = 'left')\n",
    "\n",
    "\n",
    "for i, j in rrl.iterrows():\n",
    "    if ',' in str(j['sub']):\n",
    "        subreg = str(j['sub']).replace('[', '').replace(']', '').replace(',', '|').replace(' ', '').replace(\"'\", \"\")\n",
    "    else:\n",
    "        subreg = str(j['sub']).replace('[', '').replace(']', '').replace(' ', '|').replace(\"'\", \"\")\n",
    "    rrl.loc[i, 'RULE_NAME'] = j['RULE_NAME'].split('-')[0] + '-' + subreg + '-' + j['pgr'] + '-' + j['DS'] + '-RRL'\n",
    "    \n",
    "rrl = rrl[['RULE_ID', 'CELL_AREA', 'RULE_NAME', 'ndx', 'INDEX_ID', 'INDEX_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rural x OPS\n",
    "\n",
    "fin = rrl[0:0]\n",
    "\n",
    "for i, j in rrl.iterrows():\n",
    "    wrk = parser(j['RULE_NAME'])\n",
    "    subreg = uo200['Federal Subject Number'].isin(wrk[2])\n",
    "    pgr = uo200['pgr_MT'].isin(wrk[4])\n",
    "    dist = uo200['Distance Strata'].isin(wrk[8])\n",
    "    for k in uo200['RMS_CLUSTER_CODE (ACR)'][subreg & pgr & dist].unique():\n",
    "        j['cluster'] = k\n",
    "        fin = fin.append(j)\n",
    "\n",
    "fin = fin.dropna()\n",
    "fin = fin.reset_index(drop = True)\n",
    "\n",
    "\n",
    "fin['SAMPLE_AREA_NAME'] = fin['cluster'].astype('int').astype('str') + ' ' + fin['RULE_NAME']\n",
    "#fin['SAMPLE_AREA_NAME'] = fin['SAMPLE_AREA_NAME'].str.replace('.0', '')\n",
    "\n",
    "temp = df[['RULE_ID', 'RULE_NAME']][df['RULE_TYPE'] == 'CELL_AREA'].\\\n",
    "        rename(columns = {'RULE_ID': 'CELL_AREA', 'RULE_NAME': 'REGION_NAME'}).drop_duplicates()\n",
    "\n",
    "fin = pd.merge(fin, temp, on = 'CELL_AREA', how = 'inner')\n",
    "\n",
    "#k = 0\n",
    "#for i in fin['REGION_NAME'].unique():\n",
    "#    k += 1\n",
    "#    fin.loc[fin['REGION_NAME'] == i, 'REGION_ID'] = k\n",
    "    \n",
    "#k = 0\n",
    "#for i in fin['SAMPLE_AREA_NAME'].unique():\n",
    "#    k += 1\n",
    "#    fin.loc[fin['SAMPLE_AREA_NAME'] == i, 'SAMPLE_AREA_ID'] = k\n",
    "\n",
    "fin['REGION_ID'] = 0\n",
    "fin['SAMPLE_AREA_ID'] = 0\n",
    "\n",
    "\n",
    "fin = fin.rename(columns = {'CELL_AREA': 'CELL_AREA_RULE_ID', 'RULE_ID': 'MICRO_CELL_RULE_ID'})\n",
    "\n",
    "fin = fin[['INDEX_ID', 'INDEX_NAME', 'REGION_ID', 'REGION_NAME', 'SAMPLE_AREA_ID',\n",
    "           'SAMPLE_AREA_NAME', 'CELL_AREA_RULE_ID', 'MICRO_CELL_RULE_ID']]\n",
    "\n",
    "fin = fin.drop_duplicates()\n",
    "\n",
    "fin['EXCLUDE_FLAG'] = 'N'\n",
    "fin['EXCLUSION_REASON'] = 'N'\n",
    "\n",
    "fin['INDEX_ID'] = fin['INDEX_ID'].astype('int')\n",
    "fin['REGION_ID'] = fin['REGION_ID'].astype('int')\n",
    "fin['SAMPLE_AREA_ID'] = fin['SAMPLE_AREA_ID'].astype('int')\n",
    "fin['CELL_AREA_RULE_ID'] = fin['CELL_AREA_RULE_ID'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = urbn.append(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in mapping['REGION_NAME'].unique():\n",
    "    k += 1\n",
    "    mapping.loc[mapping['REGION_NAME'] == i, 'REGION_ID'] = k\n",
    "    \n",
    "k = 0\n",
    "for i in mapping['SAMPLE_AREA_NAME'].unique():\n",
    "    k += 1\n",
    "    mapping.loc[mapping['SAMPLE_AREA_NAME'] == i, 'SAMPLE_AREA_ID'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.to_csv('mapping_new-panel_full_splitted.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
