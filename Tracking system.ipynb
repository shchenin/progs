{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dbfread import DBF\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/ScMa9004/Documents/Итоги визита/313/'\n",
    "N = 313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_excel(path + 'new_' + str(N) + '.xls', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['ocode'] = new['постоянный код новой  ТТ'].astype('str').str.slice(start = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = pd.read_excel(path + 'отчет_по_смене_характеристик_' + str(N) + '_All.xls', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = rep.rename(columns = {'Код ТТ.1': 'ocode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление из rep тех точек, которые есть в new (если тт и в rep и в new - для нас она new)\n",
    "new['outlet'] = new['постоянный код новой  ТТ'].astype('str').str.slice(start = 4)\n",
    "rep = rep[~rep['Код ТТ'].astype('str').isin(list(new['outlet'].astype('str')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Светлана Артемова\n",
    "sales_purches = pd.read_excel(path + 'метод сбора_fin_nov.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr = pd.read_csv('C:/Users/ScMa9004/Scripts/MSR.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.read_excel(path + 'panelcensus_' + str(N) + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "panrep = pd.read_excel(path + 'panel_report_00001_25.11.2019.xlsx', sheet_name = 'panel_report_00001_25.11.2019')\n",
    "panrep = panrep[['outlet', 'bst']]\n",
    "panrep = panrep.rename(columns = {'outlet': 'ocode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные о бустере в pc, new и rep неверные, а в panel report'e верные\n",
    "pc = pd.merge(pc, panrep, on = 'ocode', how = 'left').rename(columns = {'bst_y': 'bst'})\n",
    "new = pd.merge(new, panrep, on = 'ocode', how = 'left')\n",
    "rep = pd.merge(rep, panrep, on = 'ocode', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill blank 'ocode' from sliced full name (2010XXXX -> XXXX)\n",
    "pc.loc[(pc['ocode'].isna()), 'ocode'] = pc['Unnamed: 181'].str.slice(start = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_system_input(N, new, rep, sales_purches, pc):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['outlet'] = new['постоянный код новой  ТТ']\n",
    "    df['pno'] = N\n",
    "    df['region DA'] = new['регион DA']\n",
    "    df['type'] = new['Тип ТТ']\n",
    "    df['Type of info'] = new['type of info']\n",
    "    df['Source of info'] = new['sourse of info']\n",
    "    df['Interval for info'] = 'Full'\n",
    "    df['Comments for DA'] = 'new'\n",
    "    df['bst'] = new['bst']\n",
    "    \n",
    "    df['outlet'] = df['outlet'].astype('str').str.slice(start = 4)\n",
    "    \n",
    "    \n",
    "    #fill blank type of info and source of info in new from pc\n",
    "    for i in df['outlet'][df['Type of info'].isna()]:\n",
    "        df.loc[df['outlet'] == i, 'Type of info'] = pc['purchsales'][pc['ocode'] == i].iloc[0]\n",
    "    for i in df['outlet'][df['Source of info'].isna()]:\n",
    "        df.loc[df['outlet'] == i, 'Source of info'] = pc['moc'][pc['ocode'] == i].iloc[0]\n",
    "        \n",
    "    df.loc[df['Type of info'] == 1, 'Type of info'] = 'purchase'\n",
    "    df.loc[df['Type of info'] == 2, 'Type of info'] = 'sales'\n",
    "    \n",
    "    df.loc[df['Source of info'] == 4, 'Source of info'] = 'oral'\n",
    "    df.loc[df['Source of info'].isin([1, 2, 3]), 'Source of info'] = 'documented'\n",
    "    \n",
    "    rep = rep.rename(columns = {'Регион': 'region DA', 'Код ТТ': 'outlet', 'Тип ТТ': 'old_type', 'Тип ТТ.1': 'type',\\\n",
    "                            'Код бустера': 'old_bst'})\n",
    "    \n",
    "    rep['Comments for DA'] = np.nan\n",
    "    \n",
    "    rep.loc[(rep['old_type'] != rep['type']) &\\\n",
    "        ~((rep['old_type'].isin(['OLA', 'OME']) & rep['type'].isin(['OLA', 'OME'])) |\\\n",
    "        (rep['old_type'].isin(['OKS', 'OPV']) & rep['type'].isin(['OKS', 'OPV'])) |\\\n",
    "        (rep['old_type'].isin(['OMM', 'OMS']) & rep['type'].isin(['OMM', 'OMS'])) |\\\n",
    "        (rep['old_type'].isin(['DKM', 'DKP', 'DKC']) & rep['type'].isin(['DKM', 'DKP', 'DKC']))),\\\n",
    "        'Comments for DA'] = 'смена типа'\n",
    "    \n",
    "    rep.loc[(rep['old_bst'] != rep['bst']) & (rep['old_bst'] == 3) &\n",
    "            (rep['bst'].isin([1, 4, 501])), 'Comments for DA'] = 'смена бустера'\n",
    "    rep.loc[(rep['old_bst'] != rep['bst']) & (rep['old_bst'] == 4) &\n",
    "            (rep['bst'].isin([1, 3, 501])), 'Comments for DA'] = 'смена бустера'\n",
    "    rep.loc[(rep['old_bst'] != rep['bst']) & (rep['old_bst'] == 501) &\n",
    "            (rep['bst'] == 1), 'Comments for DA'] = 'смена бустера'\n",
    "    rep.loc[(rep['old_bst'] != rep['bst']) & (rep['old_bst'] == 998) &\n",
    "            (rep['bst'] == 999), 'Comments for DA'] = 'смена бустера'\n",
    "    rep.loc[(rep['old_bst'] != rep['bst']) & (rep['old_bst'] == 999) &\n",
    "            (rep['bst'] == 998), 'Comments for DA'] = 'смена бустера'\n",
    "    \n",
    "    rep = rep[rep['Comments for DA'].notna()]\n",
    "    \n",
    "    rep['pno'] = N\n",
    "    rep['Interval for info'] = 'Full'\n",
    "    \n",
    "    sales_purches = sales_purches.rename(columns = {'shop': 'outlet'})\n",
    "    sales_purches['outlet'] = sales_purches['outlet'].astype('str').str.slice(start = 4)\n",
    "    sales_purches.loc[sales_purches['total_sales_lines'] != 0, 'Type of info'] = 'sales'\n",
    "    sales_purches.loc[sales_purches['total_pur_lines'] != 0, 'Type of info'] = 'purchase'\n",
    "    sales_purches.loc[(sales_purches['total_pur_lines'] != 0) &\n",
    "                      (sales_purches['total_sales_lines'] != 0), 'Type of info'] = 'sales & purchase'\n",
    "    \n",
    "    \n",
    "    # если нет данных в файле Светланы Артемовой - информация берется из pc\n",
    "    # здесь можно сделать лучше, не ища наличие кодов тт, а просто беря их из pc\n",
    "    sales_purches.loc[(sales_purches['total_pur_lines'] == 0) &\n",
    "                (sales_purches['total_sales_lines'] == 0) &\n",
    "                (sales_purches['outlet'].astype('str').isin(list(pc['ocode'].astype('str')[pc['ocode'].astype('str').isin\\\n",
    "                (list(sales_purches['outlet'].astype('str')[(sales_purches['total_pur_lines'] == 0) &\n",
    "                (sales_purches['total_sales_lines'] == 0)])) & (pc['purchsales'] == 1)]))), 'Type of info'] = 'purchase'\n",
    "    sales_purches.loc[(sales_purches['total_pur_lines'] == 0) &\n",
    "                (sales_purches['total_sales_lines'] == 0) &\n",
    "                (sales_purches['outlet'].astype('str').isin(list(pc['ocode'].astype('str')[pc['ocode'].astype('str').isin\\\n",
    "                (list(sales_purches['outlet'].astype('str')[(sales_purches['total_pur_lines'] == 0) &\n",
    "                (sales_purches['total_sales_lines'] == 0)])) & (pc['purchsales'] == 2)]))), 'Type of info'] = 'sales'\n",
    "    \n",
    "    \n",
    "    \n",
    "    sales_purches.loc[(sales_purches['s_other_count'] /\\\n",
    "                       (sales_purches['s_other_count'] + sales_purches['s_Oral_count']) >= 0.8) &\n",
    "                      (sales_purches['Type of info'] == 'sales'), 'Source of info'] = 'documented'\n",
    "    sales_purches.loc[(sales_purches['Source of info'].isna()) &\n",
    "                      (sales_purches['Type of info'] == 'sales'), 'Source of info'] = 'oral'\n",
    "\n",
    "    sales_purches.loc[(sales_purches['pu_invoice_count'] + sales_purches['pu_other_count'] + sales_purches['pu_oral_count']) /\\\n",
    "                      (sales_purches['pu_oral_count']) >= 0.8, 'Source of info'] = 'documented'\n",
    "    sales_purches.loc[(sales_purches['Source of info'].isna()) &\n",
    "                      ((sales_purches['Type of info'] == 'purchase')), 'Source of info'] = 'oral'\n",
    "    \n",
    "    #sales_purches['Source of info'] = sales_purches['Source of info'].fillna('???')\n",
    "    \n",
    "    sales_purches = sales_purches[['outlet', 'Source of info', 'Type of info']]\n",
    "    \n",
    "    rep = rep.merge(sales_purches, on = 'outlet', how = 'inner')\n",
    "    \n",
    "    rep = rep[['outlet', 'pno', 'region DA', 'type', 'Type of info', 'Source of info',\n",
    "           'Interval for info', 'Comments for DA', 'bst']]\n",
    "    \n",
    "    df = pd.concat([df, rep], sort = False).reset_index(drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tracking_system_input(N, new, rep, sales_purches, pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr['outlet'] = msr['SMS_ID'].astype('str').str.slice(start = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr['cell'] = msr['MAS'].str.slice(start = 8).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, msr, how = 'left', on = ['outlet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status cha'] = ''\n",
    "df['Chainact'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RU_CHA'] = df['RU_CHA'].replace('OTHER', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "# fill om\n",
    "    if (row['type'] == ('OKP')) | (row['type'] == ('OTK')) | (row['type'][0] == ('D')) | (row['type'][0] == ('F')):\n",
    "        df.at[index,'om'] = 1\n",
    "    else:\n",
    "        df.at[index,'om'] = 0\n",
    "\n",
    "# fill Chainact\n",
    "    if isinstance(df['RU_CHA'], str) :\n",
    "        df.at[index,'Chainact'] = '1'\n",
    "    else:\n",
    "        df.at[index,'Chainact'] = '0'\n",
    "\n",
    "# fill status cha        \n",
    "    if isinstance(df['RU_CHA'], str) :\n",
    "        df.at[index,'status cha'] = 'check'\n",
    "    else:\n",
    "        df.at[index,'status cha'] = 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCA_PEPSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp1_c_p = pc[['ocode', 'coca', 'pepsi']].rename(columns = {'ocode': 'outlet', 'coca': 'COCA', 'pepsi': 'PEPSI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wp1 = pd.DataFrame(DBF('C:/Users/ScMa9004/Documents/Итоги визита/313/wp1.dbf', load=True))\n",
    "#wp1_c_p = wp1[['OCODE','COCA','PEPSI']]\n",
    "#wp1_c_p = wp1_c_p.rename(columns={'OCODE': 'outlet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_rum_c_p = msr.loc[(msr['INDEX_ID'] == 1000296) &\n",
    "                     msr['STORE_TYPE'].isin(['OKS','OLA','OME','OMM', 'OMS', 'OPV', 'OSM', 'OSU'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstatus_cell_coca_pepsi = pd.merge(st_rum_c_p, wp1_c_p, how = 'left', on = ['outlet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstatus_cell_coca_pepsi['excl_c_p'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill excl_c_p\n",
    "for index,row in wstatus_cell_coca_pepsi.iterrows():\n",
    "    if (row['COCA'] == 1 and row['PEPSI'] == 0):\n",
    "        wstatus_cell_coca_pepsi.at[index,'excl_c_p'] = 'coca'\n",
    "        \n",
    "    if (row['COCA'] == 0 and row['PEPSI'] == 1):\n",
    "        wstatus_cell_coca_pepsi.at[index,'excl_c_p'] = 'pepsi'\n",
    "        \n",
    "    if (row['COCA'] == 1 and row['PEPSI'] == 1):\n",
    "        wstatus_cell_coca_pepsi.at[index,'excl_c_p'] = 'blank'\n",
    "        \n",
    "    if (row['COCA'] == 0 and row['PEPSI'] == 0):\n",
    "        wstatus_cell_coca_pepsi.at[index,'excl_c_p'] = 'blank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling 'm'\n",
    "wstatus_cell_coca_pepsi['m'] = ''\n",
    "wstatus_cell_coca_pepsi['m'] = wstatus_cell_coca_pepsi['STORE_TYPE'] + '-' + wstatus_cell_coca_pepsi['TRADE_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling channel\n",
    "wstatus_cell_coca_pepsi['channel'] = ''\n",
    "\n",
    "for index,row in wstatus_cell_coca_pepsi.iterrows():\n",
    "    if (row['CITYCODE'] > 2 and row['TRADE_TYPE'] == 'TT'):\n",
    "        wstatus_cell_coca_pepsi.at[index,'channel'] = 'TT'\n",
    "        \n",
    "    if (row['CITYCODE'] > 2 and row['TRADE_TYPE'] == 'MT'):\n",
    "        wstatus_cell_coca_pepsi.at[index,'channel'] = 'MT'\n",
    "        \n",
    "    if (row['CITYCODE'] <= 2 and row['m'] in ('OKS-TT','OPV-TT')):\n",
    "        wstatus_cell_coca_pepsi.at[index,'channel'] = 'Impulse stores'\n",
    "    \n",
    "    if (row['CITYCODE'] <= 2 and row['m'] == 'OSU-MT'):\n",
    "        wstatus_cell_coca_pepsi.at[index,'channel'] = 'Supermarkets'\n",
    "        \n",
    "    if (row['CITYCODE'] <= 2 and row['m'] in ('OLA-MT', 'OME-MT', 'OMM-MT', 'OMS-MT')):\n",
    "        wstatus_cell_coca_pepsi.at[index,'channel'] = 'Supperettes'\n",
    "        \n",
    "    if (row['CITYCODE'] <= 2 and row['m'] in ('OLA-TT', 'OME-TT', 'OMM-TT', 'OMS-TT', 'OSM-TT', 'OWS-TT')):\n",
    "        wstatus_cell_coca_pepsi.at[index,'channel'] = 'Traditional Food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###менее гранулярный пгр\n",
    "wstatus_cell_coca_pepsi.loc[wstatus_cell_coca_pepsi['RU_PGR'] == '8', 'pgr'] = 4\n",
    "wstatus_cell_coca_pepsi.loc[wstatus_cell_coca_pepsi['RU_PGR'].isin(['4', '5']), 'pgr'] = 2\n",
    "wstatus_cell_coca_pepsi.loc[wstatus_cell_coca_pepsi['RU_PGR'].isin(['6', '7']), 'pgr'] = 3\n",
    "wstatus_cell_coca_pepsi.loc[wstatus_cell_coca_pepsi['RU_PGR'].isin(['1', '2', '3']), 'pgr'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling m1\n",
    "wstatus_cell_coca_pepsi['m1'] = ''\n",
    "\n",
    "for index,row in wstatus_cell_coca_pepsi.iterrows():\n",
    "    if (row['CITYCODE'] < 25):\n",
    "        wstatus_cell_coca_pepsi.at[index,'m1'] = str(row['CITYCODE']) + '-' + row['channel']\n",
    "    \n",
    "    if (row['CITYCODE'] > 24):    \n",
    "        wstatus_cell_coca_pepsi.at[index,'m1'] = row['RU_REGION'] + '-' +  str(row['pgr']).replace('.0', '') + '-' + row['channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wstatus_cell_coca_pepsi['Final Cell ID'] = wstatus_cell_coca_pepsi['MAS'].str.split('-', n = 2, expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary use this file\n",
    "cells_mbds = pd.read_excel('C:/Users/ScMa9004/Documents/RRES/FMCG_Urban_RES_db_Community_File_cut.xlsx')\n",
    "pr = pd.read_excel(path + 'Panel Russia_for 313.xlsx', sheet_name = 'Panel', skiprows = 2)\n",
    "pr_for_AP_cha = pr\n",
    "pr_map = pr[['MAS', 'CELL_ID']].rename(columns = {'MAS': 'cell'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pd.pivot_table(pr, index = 'CELL_ID', values = 'act stand', aggfunc = np.sum).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_mbds = pd.pivot_table(cells_mbds, index = 'Final Cell ID', values = 'UNIVERSE', aggfunc = np.sum).reset_index(drop = False)\n",
    "cells_mbds = cells_mbds.rename(columns = {'Final Cell ID': 'CELL_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_mbds = pd.merge(cells_mbds, pr, how = 'left', on = 'CELL_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_mbds['Zf'] = cells_mbds['UNIVERSE'] / cells_mbds['act stand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cells_mbds = cells_mbds[['CELL_ID', 'Zf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wstatus_cell_coca_pepsi = pd.merge(wstatus_cell_coca_pepsi, pr_map, how = 'inner', on = 'cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstatus_cell_coca_pepsi = pd.merge(wstatus_cell_coca_pepsi, cells_mbds, how = 'inner', on = ['CELL_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pivot table for coca & pepsi check\n",
    "pivot_c_p = pd.pivot_table(wstatus_cell_coca_pepsi, values='Zf', index='m1', columns='excl_c_p', aggfunc=np.sum)\n",
    "\n",
    "#turning NaN into 0\n",
    "pivot_c_p[np.isnan(pivot_c_p)] = 0\n",
    "\n",
    "# adding total\n",
    "pivot_c_p['total'] = pivot_c_p['coca'] + pivot_c_p['pepsi'] + pivot_c_p['blank']\n",
    "\n",
    "#calculating coca_panel and pepsi_panel\n",
    "pivot_c_p['coca_panel'] = pivot_c_p['coca'] / pivot_c_p['total']\n",
    "pivot_c_p['pepsi_panel'] = pivot_c_p['pepsi'] / pivot_c_p['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading universe file\n",
    "universe_c_p = pd.read_excel('C:/Users/ScMa9004/Scripts/universe_coca_pepsi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vlookup universe to pivot table\n",
    "pivot_c_p = pd.merge(pivot_c_p, universe_c_p, how = 'left', on = ['m1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coca check\n",
    "for index,row in pivot_c_p.iterrows():\n",
    "    if (row['coca_panel'] < (row['coca_universe'] - 0.05)):\n",
    "        pivot_c_p.at[index,'coca_check'] = 'too little'\n",
    "         \n",
    "    if (row['coca_panel'] >= (row['coca_universe'] - 0.05)) and (row['coca_panel'] <= (row['coca_universe'] + 0.05)):\n",
    "        pivot_c_p.at[index,'coca_check'] = 'neutral'\n",
    "         \n",
    "    if (row['coca_panel'] > (row['coca_universe'] + 0.05)):\n",
    "        pivot_c_p.at[index,'coca_check'] = 'coca_over'\n",
    "\n",
    "# pepsi check\n",
    "for index,row in pivot_c_p.iterrows():\n",
    "    if (row['pepsi_panel'] < (row['pepsi_universe'] - 0.05)):\n",
    "        pivot_c_p.at[index,'pepsi_check'] = 'too little'\n",
    "         \n",
    "    if (row['pepsi_panel'] >= (row['pepsi_universe'] - 0.05)) and (row['pepsi_panel'] <= (row['pepsi_universe'] + 0.05)):\n",
    "        pivot_c_p.at[index,'pepsi_check'] = 'neutral'\n",
    "         \n",
    "    if (row['pepsi_panel'] > (row['pepsi_universe'] + 0.05)):\n",
    "        pivot_c_p.at[index,'pepsi_check'] = 'pepsi_over'\n",
    "\n",
    "# saving pivot table         \n",
    "writer = pd.ExcelWriter('pivot_c_p.xlsx')\n",
    "pivot_c_p.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# selecting columns from pivot table with check results\n",
    "pivot_c_p = pivot_c_p[['m1', 'coca_check', 'pepsi_check']]\n",
    "\n",
    "#vlookup check results from the pivot table to wstatus_cell_excl_coca_pepsi\n",
    "wstatus_cell_coca_pepsi = pd.merge(wstatus_cell_coca_pepsi, pivot_c_p, how='left', on=['m1'])\n",
    "\n",
    "for index,row in wstatus_cell_coca_pepsi.iterrows():\n",
    "    if ((row['excl_c_p'] == 'blank') or (row['excl_c_p'] == 'pepsi')):\n",
    "        wstatus_cell_coca_pepsi.at[index,'coca_check'] = ''\n",
    "    if ((row['excl_c_p'] == 'blank') or (row['excl_c_p'] == 'coca')):\n",
    "        wstatus_cell_coca_pepsi.at[index,'pepsi_check'] = ''\n",
    "\n",
    "writer = pd.ExcelWriter('wstatus_cell_coca_pepsi.xlsx')\n",
    "wstatus_cell_coca_pepsi.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# vlookup coca_check and pepsi_check to tracking system\n",
    "wstatus_cell_coca_pepsi_result = wstatus_cell_coca_pepsi[['outlet', 'coca_check', 'pepsi_check']]\n",
    "result = pd.merge(result, wstatus_cell_coca_pepsi_result, how = 'left', on = ['outlet'])\n",
    "\n",
    "# fill final status for coca & pepsi check\n",
    "result['status_coca_pepsi'] = ''\n",
    "\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'status_coca_pepsi'] = 'neutral' \n",
    "    if ((row['coca_check'] == 'too little') or (row['pepsi_check'] == 'too little')):\n",
    "        result.at[index,'status_coca_pepsi'] = 'OK'\n",
    "    if ((row['coca_check'] == 'coca_over') or (row['pepsi_check'] == 'pepsi_over')):\n",
    "        result.at[index,'status_coca_pepsi'] = 'No'\n",
    "\n",
    "# saving tracking system with coca & pepsi check\n",
    "#writer = pd.ExcelWriter('main.xlsx')\n",
    "#result.to_excel(writer,'Sheet1')\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(result, wstatus_cell_coca_pepsi[['outlet', 'm1']], on = 'outlet', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BABY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baby checks\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "# import wp1 and st_rum\n",
    "#st_rum = pd.read_excel('st_rum_296_1.xls',sheetname='st_rum_296_1')\n",
    "#wp1 = pd.read_excel('wp1.xlsx',sheetname='wp1')\n",
    "\n",
    "# select bst = 001 and only OBS from st_rum\n",
    "st_rum_baby = msr.loc[(msr['INDEX_ID'] == 1000296) & msr['STORE_TYPE'].isin(['OBS'])]\n",
    "\n",
    "# add columns baby_f and baby_d to st_rum from wp1\n",
    "wp1_baby = wp1[['OCODE','HL141','HL088']]\n",
    "wp1_baby = wp1_baby.rename(columns={'OCODE': 'outlet', 'HL141': 'baby_f', 'HL088': 'baby_d'})\n",
    "wstatus_cell_baby = pd.merge(st_rum_baby, wp1_baby, how = 'left', on = ['outlet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wstatus_cell_baby['CELL_ID'] = wstatus_cell_baby['MAS'].str.split('-', n = 2, expand = True)[0].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstatus_cell_baby = pd.merge(wstatus_cell_baby, cells_mbds, how = 'left', on = ['CELL_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in wstatus_cell_baby.iterrows():\n",
    "    wstatus_cell_baby.at[index,'z_baby_f'] = row['Zf'] * row['baby_f']\n",
    "    wstatus_cell_baby.at[index,'z_baby_d'] = row['Zf'] * row['baby_d']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###менее гранулярный пгр\n",
    "wstatus_cell_baby.loc[wstatus_cell_baby['RU_PGR'] == '8', 'pgr'] = 4\n",
    "wstatus_cell_baby.loc[wstatus_cell_baby['RU_PGR'].isin(['4', '5']), 'pgr'] = 2\n",
    "wstatus_cell_baby.loc[wstatus_cell_baby['RU_PGR'].isin(['6', '7']), 'pgr'] = 3\n",
    "wstatus_cell_baby.loc[wstatus_cell_baby['RU_PGR'].isin(['1', '2', '3']), 'pgr'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstatus_cell_baby['merge'] = ''\n",
    "\n",
    "for index,row in wstatus_cell_baby.iterrows():\n",
    "    if (row['CITYCODE'] < 25):\n",
    "        wstatus_cell_baby.at[index,'merge'] = str(row['CITYCODE'])\n",
    "             \n",
    "    if (row['CITYCODE'] > 24):\n",
    "        wstatus_cell_baby.at[index,'merge'] = row['RU_REGION'] + '-' + str(row['pgr']).replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pivot table for baby food & baby drug\n",
    "pivot_baby_f = pd.pivot_table(wstatus_cell_baby, values='z_baby_f', index='merge', aggfunc=np.sum)\n",
    "\n",
    "pivot_baby_d = pd.pivot_table(wstatus_cell_baby, values='z_baby_d', index='merge', aggfunc=np.sum)\n",
    "\n",
    "pivot_baby = pd.pivot_table(wstatus_cell_baby, values='Zf', index='merge', aggfunc=np.sum)\n",
    "\n",
    "#turning NaN into 0\n",
    "pivot_baby_f[np.isnan(pivot_baby_f)] = 0\n",
    "pivot_baby_d[np.isnan(pivot_baby_d)] = 0\n",
    "pivot_baby[np.isnan(pivot_baby)] = 0\n",
    "\n",
    "#saving the pivot tables in a separate file\n",
    "writer = pd.ExcelWriter('pivot_baby_f.xlsx')\n",
    "pivot_baby_f.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter('pivot_baby_d.xlsx')\n",
    "pivot_baby_d.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter('pivot_baby.xlsx')\n",
    "pivot_baby.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "#reading the pivot tables from the files\n",
    "pivot_baby_f = pd.read_excel('pivot_baby_f.xlsx',sheet_name='Sheet1')\n",
    "pivot_baby_d = pd.read_excel('pivot_baby_d.xlsx',sheet_name='Sheet1')\n",
    "pivot_baby = pd.read_excel('pivot_baby.xlsx',sheet_name='Sheet1')\n",
    "\n",
    "#merge pivot tables\n",
    "pivot_baby_all = pd.merge(pivot_baby_f, pivot_baby_d, how = 'left', on = ['merge'])\n",
    "pivot_baby_all = pd.merge(pivot_baby_all, pivot_baby, how = 'left', on = ['merge'])\n",
    "\n",
    "#saving the total pivot table in a separate file\n",
    "writer = pd.ExcelWriter('pivot_baby_all.xlsx')\n",
    "pivot_baby_all.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "#reading the pivot table from the file\n",
    "pivot_baby_all = pd.read_excel('pivot_baby_all.xlsx',sheet_name='Sheet1')\n",
    "\n",
    "# calculating baby_f_panel and baby_d_panel\n",
    "pivot_baby_all['baby_f_panel'] = pivot_baby_all['z_baby_f'] / pivot_baby_all['Zf']\n",
    "pivot_baby_all['baby_d_panel'] = pivot_baby_all['z_baby_d'] / pivot_baby_all['Zf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_baby = pd.read_excel('C:/Users/ScMa9004/Scripts/universe_baby.xlsx',sheet_name='Sheet1')\n",
    "\n",
    "pivot_baby_all = pd.merge(pivot_baby_all, universe_baby, how = 'left', on = ['merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baby_f check\n",
    "for index,row in pivot_baby_all.iterrows():\n",
    "    if (row['baby_f_panel'] < (row['universe_baby_f'] - 0.05)):\n",
    "        pivot_baby_all.at[index,'baby_f_check'] = 'too little'\n",
    "         \n",
    "    if (row['baby_f_panel'] >= (row['universe_baby_f'] - 0.05)) and (row['baby_f_panel'] <= (row['universe_baby_f'] + 0.05)):\n",
    "        pivot_baby_all.at[index,'baby_f_check'] = 'neutral'\n",
    "         \n",
    "    if (row['baby_f_panel'] > (row['universe_baby_f'] + 0.05)):\n",
    "        pivot_baby_all.at[index,'baby_f_check'] = 'baby_f_over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baby_d check\n",
    "for index,row in pivot_baby_all.iterrows():\n",
    "    if (row['baby_d_panel'] < (row['universe_baby_d'] - 0.05)):\n",
    "        pivot_baby_all.at[index,'baby_d_check'] = 'too little'\n",
    "         \n",
    "    if (row['baby_d_panel'] >= (row['universe_baby_d'] - 0.05)) and (row['baby_d_panel'] <= (row['universe_baby_d'] + 0.05)):\n",
    "        pivot_baby_all.at[index,'baby_d_check'] = 'neutral'\n",
    "         \n",
    "    if (row['baby_d_panel'] > (row['universe_baby_d'] + 0.05)):\n",
    "        pivot_baby_all.at[index,'baby_d_check'] = 'baby_d_over'\n",
    "         \n",
    "#saving the total pivot table in a separate file\n",
    "writer = pd.ExcelWriter('pivot_baby_all.xlsx')\n",
    "pivot_baby_all.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns from pivot table with check results\n",
    "pivot_baby_all = pivot_baby_all[['merge', 'baby_f_check', 'baby_d_check']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup check results from the pivot table to wstatus_cell_baby\n",
    "wstatus_cell_baby = pd.merge(wstatus_cell_baby, pivot_baby_all, how='left', on=['merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in wstatus_cell_baby.iterrows():\n",
    "    if (row['baby_f'] == 0):\n",
    "        wstatus_cell_baby.at[index,'baby_f_check'] = 'neutral'\n",
    "    if (row['baby_d'] == 0):\n",
    "        wstatus_cell_baby.at[index,'baby_d_check'] = 'neutral'\n",
    "\n",
    "writer = pd.ExcelWriter('wstatus_cell_baby.xlsx')\n",
    "wstatus_cell_baby.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# vlookup baby_f_check and baby_d_check to tracking system\n",
    "wstatus_cell_baby_result = wstatus_cell_baby[['outlet', 'baby_f_check', 'baby_d_check']]\n",
    "result = pd.merge(result, wstatus_cell_baby_result, how = 'left', on = ['outlet'])\n",
    "\n",
    "# fill final status for baby_f & baby_d check\n",
    "result['status_baby'] = ''\n",
    "\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'status_baby'] = 'neutral' \n",
    "    if ((row['baby_f_check'] == 'too little') or (row['baby_d_check'] == 'too little')):\n",
    "         result.at[index,'status_baby'] = 'OK'\n",
    "    if ((row['baby_f_check'] == 'baby_f_over') or (row['baby_d_check'] == 'baby_d_over')):\n",
    "         result.at[index,'status_baby'] = 'No'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHA CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import universe for cha checks\n",
    "cha_universe_fmcg = pd.read_excel('C:/Users/ScMa9004/Scripts/cha_check_universe.xlsx',sheet_name='fmcg')   \n",
    "cha_universe_cig = pd.read_excel('C:/Users/ScMa9004/Scripts/cha_check_universe.xlsx',sheet_name='cig')\n",
    "cha_universe_beer = pd.read_excel('C:/Users/ScMa9004/Scripts/cha_check_universe.xlsx',sheet_name='beer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pivot tables for madras cells\n",
    "pivot_universe_fmcg = pd.pivot_table(cha_universe_fmcg, values='NUHTRP Final', index='Final Cell ID', aggfunc=np.sum)\n",
    "pivot_universe_cig = pd.pivot_table(cha_universe_cig, values='NUHTRP Final', index='Final Cell ID', aggfunc=np.sum)\n",
    "pivot_universe_beer = pd.pivot_table(cha_universe_beer, values='NUHTRP Final', index='Final Cell ID', aggfunc=np.sum)\n",
    "pivot_universe_fmcg = pivot_universe_fmcg.rename(columns = {'NUHTRP Final': 'Sum of universe fmcg'})\n",
    "pivot_universe_cig = pivot_universe_cig.rename(columns = {'NUHTRP Final': 'Sum of universe cig'})\n",
    "pivot_universe_beer = pivot_universe_beer.rename(columns = {'NUHTRP Final': 'Sum of universe beer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the pivot tables in separate files\n",
    "writer = pd.ExcelWriter('pivot_universe_fmcg.xlsx')\n",
    "pivot_universe_fmcg.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('pivot_universe_cig.xlsx')\n",
    "pivot_universe_cig.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('pivot_universe_beer.xlsx')\n",
    "pivot_universe_beer.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "#reading the pivot table from the file\n",
    "pivot_universe_fmcg = pd.read_excel('pivot_universe_fmcg.xlsx',sheet_name='Sheet1')\n",
    "pivot_universe_cig = pd.read_excel('pivot_universe_cig.xlsx',sheet_name='Sheet1')\n",
    "pivot_universe_beer = pd.read_excel('pivot_universe_beer.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.loc[result['cha'].isna(), 'cha'] = 'Standalone'\n",
    "result.loc[result['INDEX_ID'] == 1000296, 'key_fmcg'] = result['MAS'].str.split('-', n = 2, expand = True)[0].astype('str') + '-' + result['cha'].astype('str')\n",
    "result.loc[result['INDEX_ID'] == 1000334, 'key_cig'] = result['MAS'].str.split('-', n = 2, expand = True)[0].astype('str') + '-' + result['cha'].astype('str')\n",
    "result.loc[result['INDEX_ID'] == 1000328, 'key_beer'] = result['MAS'].str.split('-', n = 2, expand = True)[0].astype('str') + '-' + result['cha'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cha_universe_fmcg['key_fmcg'] = cha_universe_fmcg['Final Cell ID'].astype('str') + '-' + cha_universe_fmcg['cha'].astype('str')\n",
    "cha_universe_cig['key_cig'] = cha_universe_cig['Final Cell ID'].astype('str') + '-' + cha_universe_cig['cha'].astype('str')\n",
    "cha_universe_beer['key_beer'] = cha_universe_beer['Final Cell ID'].astype('str') + '-' + cha_universe_beer['cha'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns from cha_universe\n",
    "cha_universe_fmcg = cha_universe_fmcg[['key_fmcg', 'NUHTRP Final']]\n",
    "cha_universe_cig = cha_universe_cig[['key_cig', 'NUHTRP Final']]\n",
    "cha_universe_beer = cha_universe_beer[['key_beer', 'NUHTRP Final']]\n",
    "cha_universe_fmcg = cha_universe_fmcg.rename(columns = {'NUHTRP Final': 'Sum of universe fmcg'})\n",
    "cha_universe_cig = cha_universe_cig.rename(columns = {'NUHTRP Final': 'Sum of universe cig'})\n",
    "cha_universe_beer = cha_universe_beer.rename(columns = {'NUHTRP Final': 'Sum of universe beer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "cha_universe_fmcg = pd.pivot_table(cha_universe_fmcg, index = 'key_fmcg', values = 'Sum of universe fmcg', aggfunc = np.sum).reset_index()\n",
    "cha_universe_cig = pd.pivot_table(cha_universe_cig, index = 'key_cig', values = 'Sum of universe cig', aggfunc = np.sum).reset_index()\n",
    "cha_universe_beer = pd.pivot_table(cha_universe_beer, index = 'key_beer', values = 'Sum of universe beer', aggfunc = np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Final Cell ID'] = result['MAS'].str.split('-', n = 2, expand = True)[0].replace(np.nan, 0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vlookup cha & cell universe to final file \n",
    "result = pd.merge(result, pivot_universe_fmcg, how = 'left', on = ['Final Cell ID'])\n",
    "result = pd.merge(result, pivot_universe_cig, how = 'left', on = ['Final Cell ID'])\n",
    "result = pd.merge(result, pivot_universe_beer, how = 'left', on = ['Final Cell ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(result, cha_universe_fmcg, how = 'left', on = ['key_fmcg'])\n",
    "result = pd.merge(result, cha_universe_cig, how = 'left', on = ['key_cig'])\n",
    "result = pd.merge(result, cha_universe_beer, how = 'left', on = ['key_beer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('main.xlsx')\n",
    "result.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in result.iterrows():\n",
    "    if math.isnan(row['Sum of universe fmcg_x']):\n",
    "        result.at[index, 'Sum of universe fmcg_x'] = '0'\n",
    "    if math.isnan(row['Sum of universe cig_x']):\n",
    "        result.at[index, 'Sum of universe cig_x'] = '0'\n",
    "    if math.isnan(row['Sum of universe beer_x']):\n",
    "        result.at[index, 'Sum of universe beer_x'] = '0'\n",
    "    if math.isnan(row['Sum of universe fmcg_y']):\n",
    "        result.at[index, 'Sum of universe fmcg_y'] = '0'\n",
    "    if math.isnan(row['Sum of universe cig_y']):\n",
    "        result.at[index, 'Sum of universe cig_y'] = '0'\n",
    "    if math.isnan(row['Sum of universe beer_y']):\n",
    "        result.at[index, 'Sum of universe beer_y'] = '0'\n",
    "\n",
    "result = result.rename(columns={'Sum of universe fmcg_x': 'universe fmcg', 'Sum of universe cig_x': 'universe cig', 'Sum of universe beer_x': 'universe beer'})\n",
    "result = result.rename(columns={'Sum of universe fmcg_y': 'universe fmcg cha', 'Sum of universe cig_y': 'universe cig cha', 'Sum of universe beer_y': 'universe beer cha'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_OP = pd.read_excel('C:/Users/ScMa9004/Scripts/OP.xlsx')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# AP_cha_micro\n",
    "pc = pc[pc['ST'] != 'P']\n",
    "\n",
    "pc.loc[pc['mt'] == False, 'mt'] = 'TT'\n",
    "pc.loc[pc['mt'] == True, 'mt'] = 'MT'\n",
    "#pc = pc[pc['chainact'] == 1]\n",
    "\n",
    "pc['key'] = pc['citycode'].astype('str') + ' ' + pc['type1'] + ' ' + pc['mt'] + ' ' + pc['hip'].astype('str').str.replace('nan', '') + ' '\n",
    "\n",
    "wrk = pd.merge(pc[['cha', 'key', 'chainact']], pr_for_AP_cha[['key', 'MAS']], how = 'inner')\n",
    "wrk['cha'] = wrk['cha'].fillna('nan')\n",
    "AP_cha_fmcg = pd.pivot_table(wrk, index = ['MAS', 'key', 'cha'],\n",
    "                             values = 'chainact', \n",
    "                             aggfunc = 'count').reset_index(drop = False)\n",
    "AP_cha_fmcg = AP_cha_fmcg[AP_cha_fmcg['MAS'] != 0]\n",
    "AP_cha_fmcg['key_cha'] = AP_cha_fmcg['MAS'].astype('int').astype('str') + '-' + AP_cha_fmcg['cha']\n",
    "AP_cha_fmcg = AP_cha_fmcg.rename(columns = {'MAS': 'cell', 'chainact': 'AP_cha_fmcg'})\n",
    "ap_cha_fmcg = AP_cha_fmcg[['key_cha', 'AP_cha_fmcg']]\n",
    "ap_cha_fmcg = pd.pivot_table(ap_cha_fmcg, index = 'key_cha', values = 'AP_cha_fmcg', aggfunc = np.sum).reset_index()\n",
    "\n",
    "wrk = pd.merge(pc[['cha', 'key', 'chainact']], pr_for_AP_cha[['key', 'MAS.1']], how = 'inner')\n",
    "wrk['cha'] = wrk['cha'].fillna('nan')\n",
    "AP_cha_cig = pd.pivot_table(wrk, index = ['MAS.1', 'key', 'cha'],\n",
    "                            values = 'chainact',\n",
    "                            aggfunc = 'count').reset_index(drop = False)\n",
    "AP_cha_cig = AP_cha_cig[AP_cha_cig['MAS.1'] != 0]\n",
    "AP_cha_cig['key_cha'] = AP_cha_cig['MAS.1'].astype('int').astype('str') + '-' + AP_cha_cig['cha']\n",
    "AP_cha_cig = AP_cha_cig.rename(columns = {'MAS.1': 'cell', 'chainact': 'AP_cha_cig'})\n",
    "ap_cha_cig = AP_cha_cig[['key_cha', 'AP_cha_cig']]\n",
    "ap_cha_cig = pd.pivot_table(ap_cha_cig, index = 'key_cha', values = 'AP_cha_cig', aggfunc = np.sum).reset_index()\n",
    "\n",
    "wrk = pd.merge(pc[['cha', 'key', 'chainact']], pr_for_AP_cha[['key', 'MAS.2']], how = 'inner')\n",
    "wrk['cha'] = wrk['cha'].fillna('nan')\n",
    "AP_cha_beer = pd.pivot_table(wrk, index = ['MAS.2', 'key', 'cha'],\n",
    "                             values = 'chainact', \n",
    "                             aggfunc = np.sum).reset_index(drop = False)\n",
    "AP_cha_beer = AP_cha_beer[AP_cha_beer['MAS.2'] != 0]\n",
    "AP_cha_beer['key_cha'] = AP_cha_beer['MAS.2'].astype('int').astype('str') + '-' + AP_cha_beer['cha']\n",
    "AP_cha_beer = AP_cha_beer.rename(columns = {'MAS.2': 'cell', 'chainact': 'AP_cha_beer'})\n",
    "ap_cha_beer = AP_cha_beer[['key_cha', 'AP_cha_beer']]\n",
    "ap_cha_beer = pd.pivot_table(ap_cha_beer, index = 'key_cha', values = 'AP_cha_beer', aggfunc = np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ScMa9004\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# AP_cha_madras\n",
    "\n",
    "#Колонка должна называться ST, но иногда она без названия\n",
    "pc = pc[pc['ST'] != 'P']\n",
    "#pc = pc[pc['Unnamed: 183'] != 'P']\n",
    "\n",
    "\n",
    "pc.loc[pc['mt'] == False, 'mt'] = 'TT'\n",
    "pc.loc[pc['mt'] == True, 'mt'] = 'MT'\n",
    "#pc = pc[pc['chainact'] == 1]\n",
    "\n",
    "pc['key'] = pc['citycode'].astype('str') + ' ' + pc['type1'] + ' ' + pc['mt'] + ' ' + pc['hip'].astype('str').str.replace('nan', '') + ' '\n",
    "\n",
    "wrk = pd.merge(pc[['cha', 'key', 'chainact']], pr_for_AP_cha[['key', 'CELL_ID']], how = 'inner')\n",
    "wrk['cha'] = wrk['cha'].fillna('nan')\n",
    "AP_cha_fmcg = pd.pivot_table(wrk, index = ['CELL_ID', 'key', 'cha'],\n",
    "                             values = 'chainact', \n",
    "                             aggfunc = 'count').reset_index(drop = False)\n",
    "AP_cha_fmcg = AP_cha_fmcg[AP_cha_fmcg['CELL_ID'] != 0]\n",
    "AP_cha_fmcg['key_cha'] = AP_cha_fmcg['CELL_ID'].astype('int').astype('str') + '-' + AP_cha_fmcg['cha']\n",
    "AP_cha_fmcg = AP_cha_fmcg.rename(columns = {'CELL_ID': 'cell', 'chainact': 'AP_cha_fmcg'})\n",
    "ap_cha_fmcg = AP_cha_fmcg[['key_cha', 'AP_cha_fmcg']]\n",
    "ap_cha_fmcg = pd.pivot_table(ap_cha_fmcg, index = 'key_cha', values = 'AP_cha_fmcg', aggfunc = np.sum).reset_index()\n",
    "\n",
    "wrk = pd.merge(pc[['cha', 'key', 'chainact']], pr_for_AP_cha[['key', 'CELL_ID.1']], how = 'inner')\n",
    "wrk['cha'] = wrk['cha'].fillna('nan')\n",
    "AP_cha_cig = pd.pivot_table(wrk, index = ['CELL_ID.1', 'key', 'cha'],\n",
    "                            values = 'chainact',\n",
    "                            aggfunc = 'count').reset_index(drop = False)\n",
    "AP_cha_cig = AP_cha_cig[AP_cha_cig['CELL_ID.1'] != 0]\n",
    "AP_cha_cig['key_cha'] = AP_cha_cig['CELL_ID.1'].astype('int').astype('str') + '-' + AP_cha_cig['cha']\n",
    "AP_cha_cig = AP_cha_cig.rename(columns = {'CELL_ID.1': 'cell', 'chainact': 'AP_cha_cig'})\n",
    "ap_cha_cig = AP_cha_cig[['key_cha', 'AP_cha_cig']]\n",
    "ap_cha_cig = pd.pivot_table(ap_cha_cig, index = 'key_cha', values = 'AP_cha_cig', aggfunc = np.sum).reset_index()\n",
    "\n",
    "wrk = pd.merge(pc[['cha', 'key', 'chainact']], pr_for_AP_cha[['key', 'CELL_ID.2']], how = 'inner')\n",
    "wrk['cha'] = wrk['cha'].fillna('nan')\n",
    "AP_cha_beer = pd.pivot_table(wrk, index = ['CELL_ID.2', 'key', 'cha'],\n",
    "                             values = 'chainact', \n",
    "                             aggfunc = np.sum).reset_index(drop = False)\n",
    "AP_cha_beer = AP_cha_beer[AP_cha_beer['CELL_ID.2'] != 0]\n",
    "AP_cha_beer['key_cha'] = AP_cha_beer['CELL_ID.2'].astype('int').astype('str') + '-' + AP_cha_beer['cha']\n",
    "AP_cha_beer = AP_cha_beer.rename(columns = {'CELL_ID.2': 'cell', 'chainact': 'AP_cha_beer'})\n",
    "ap_cha_beer = AP_cha_beer[['key_cha', 'AP_cha_beer']]\n",
    "ap_cha_beer = pd.pivot_table(ap_cha_beer, index = 'key_cha', values = 'AP_cha_beer', aggfunc = np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['cha'] = result['cha'].str.replace('Standalone', 'nan')\n",
    "#result['key_cha'] = result['cell'].astype('str') + '-' + result['cha']\n",
    "result['key_cha'] = result['Final Cell ID'].astype('str') + '-' + result['cha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vlookup OP and AP_cha    \n",
    "result = pd.merge(result, AP_OP, how = 'left', on = ['cell'])\n",
    "result = pd.merge(result, ap_cha_fmcg, how = 'left', on = ['key_cha'])\n",
    "result = pd.merge(result, ap_cha_cig, how = 'left', on = ['key_cha'])\n",
    "result = pd.merge(result, ap_cha_beer, how = 'left', on = ['key_cha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('main.xlsx')\n",
    "result.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "for index,row in result.iterrows():\n",
    "    if math.isnan(row['AP_fmcg']):\n",
    "        result.loc[index, 'AP_fmcg'] = 0\n",
    "    if math.isnan(row['AP_cig']):\n",
    "        result.loc[index, 'AP_cig'] = 0\n",
    "    if math.isnan(row['AP_beer']):\n",
    "        result.loc[index, 'AP_beer'] = 0\n",
    "    if math.isnan(row['AP_fmcg']):\n",
    "        result.loc[index, 'AP_cha_fmcg'] = 0\n",
    "    if math.isnan(row['AP_cha_cig']):\n",
    "        result.loc[index, 'AP_cha_cig'] = 0\n",
    "    if math.isnan(row['AP_cha_beer']):\n",
    "        result.loc[index, 'AP_cha_beer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.loc[result['universe cig'] == 0, 'universe cig'] = np.nan\n",
    "result.loc[result['universe beer'] == 0, 'universe beer'] = np.nan\n",
    "result.loc[result['universe fmcg'] == 0, 'universe fmcg'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate possible_no_cha\n",
    "#for index,row in result.iterrows():\n",
    "#    if (row['bst'] == 1 and isinstance(row['cha'], str)):\n",
    "#        if (row['universe fmcg cha']/row['universe fmcg']*row['OP_fmcg'] < 1):\n",
    "#            result.at[index, 'possible_fmcg'] = 1\n",
    "#        else:\n",
    "#            result.at[index, 'possible_fmcg'] = row['universe fmcg cha']/row['universe fmcg']*row['OP_fmcg']\n",
    "#    writer = pd.ExcelWriter('main.xlsx')\n",
    "#    result.to_excel(writer,'Sheet1')\n",
    "#    writer.save()\n",
    "#\n",
    "#    if ((row['bst'] == 3 or row['bst'] == 501 or row['bst'] == 502) and isinstance(row['cha'], str)):\n",
    "#        if (row['universe cig cha']/row['universe cig']*row['OP_cig'] < 1):\n",
    "#            result.at[index, 'possible_cig'] = 1\n",
    "#        else:\n",
    "#            result.at[index, 'possible_cig'] = row['universe cig cha']/row['universe cig']*row['OP_cig']\n",
    "#    writer = pd.ExcelWriter('main.xlsx')\n",
    "#    result.to_excel(writer,'Sheet1')\n",
    "#    writer.save()\n",
    "#    \n",
    "#    if ((row['bst'] == 4 or row['bst'] == 501) and isinstance(row['cha'], str)):\n",
    "#        if (row['universe beer cha']/row['universe beer']*row['OP_beer'] < 1):\n",
    "#            result.at[index, 'possible_beer'] = 1\n",
    "#        else:\n",
    "#            result.at[index, 'possible_beer'] = row['universe beer cha']/row['universe beer']*row['OP_beer']\n",
    "#    writer = pd.ExcelWriter('main.xlsx')\n",
    "#    result.to_excel(writer,'Sheet1')\n",
    "#    writer.save()   \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate possible_no_cha\n",
    "for index,row in result.iterrows():\n",
    "    if (row['INDEX_ID'] == 1000296 and isinstance(row['cha'], str)):\n",
    "        if (row['universe fmcg cha']/row['universe fmcg']*row['AP_fmcg'] < 1):\n",
    "            result.at[index, 'possible_fmcg'] = 1\n",
    "        else:\n",
    "            result.at[index, 'possible_fmcg'] = row['universe fmcg cha']/row['universe fmcg']*row['AP_fmcg']\n",
    "#    writer = pd.ExcelWriter('main.xlsx')\n",
    "#    result.to_excel(writer,'Sheet1')\n",
    "#    writer.save()\n",
    "\n",
    "    if (row['INDEX_ID'] == 1000334 and isinstance(row['cha'], str)):\n",
    "        if (row['universe cig cha']/row['universe cig']*row['AP_cig'] < 1):\n",
    "            result.at[index, 'possible_cig'] = 1\n",
    "        else:\n",
    "            result.at[index, 'possible_cig'] = row['universe cig cha']/row['universe cig']*row['AP_cig']\n",
    "#    writer = pd.ExcelWriter('main.xlsx')\n",
    "#    result.to_excel(writer,'Sheet1')\n",
    "#    writer.save()\n",
    "    \n",
    "    if (row['INDEX_ID'] == 1000328 and isinstance(row['cha'], str)):\n",
    "        if (row['universe beer cha']/row['universe beer']*row['AP_beer'] < 1):\n",
    "            result.at[index, 'possible_beer'] = 1\n",
    "        else:\n",
    "            result.at[index, 'possible_beer'] = row['universe beer cha']/row['universe beer']*row['AP_beer']\n",
    "#    writer = pd.ExcelWriter('main.xlsx')\n",
    "#    result.to_excel(writer,'Sheet1')\n",
    "#    writer.save()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in result.iterrows():\n",
    "    if math.isnan(row['possible_fmcg']):\n",
    "        result.at[index, 'possible_fmcg'] = 0\n",
    "    if math.isnan(row['possible_cig']):\n",
    "        result.at[index, 'possible_cig'] = 0\n",
    "    if math.isnan(row['possible_beer']):\n",
    "        result.at[index, 'possible_beer'] = 0 \n",
    "        \n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'possible_fmcg'] = round(row['possible_fmcg'],0)\n",
    "    result.at[index,'possible_cig'] = round(row['possible_cig'],0)\n",
    "    result.at[index,'possible_beer'] = round(row['possible_beer'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['cha'] = result['cha'].replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ДЕЛЕНИЕ НА НОЛЬ\n",
    "result.loc[(result['AP_fmcg'] == 0) & (result['AP_cha_fmcg'] == 0), 'AP_fmcg'] = 9999\n",
    "result.loc[(result['AP_cig'] == 0) & (result['AP_cha_cig'] == 0), 'AP_cig'] = 9999\n",
    "result.loc[(result['AP_beer'] == 0) & (result['AP_cha_beer'] == 0), 'AP_beer'] = 9999\n",
    "\n",
    "for index,row in result.iterrows():\n",
    "    if ((row['INDEX_ID'] == 1000296) and (row['bst'] == 1) and isinstance(row['cha'], str)):    \n",
    "        if ((row['AP_cha_fmcg']/row['AP_fmcg'] <= 0.5) or (row['AP_cha_fmcg'] == 1) or (row['AP_cha_fmcg'] <= row['possible_fmcg'])) :\n",
    "            result.at[index, 'status cha'] = 'OK'\n",
    "        else:\n",
    "            result.at[index, 'status cha'] = 'no'\n",
    "    \n",
    "    if ((row['INDEX_ID'] == 1000334) and ((row['bst'] == 3) or (row['bst'] == 501) or (row['bst'] == 502)) and isinstance(row['cha'], str)):    \n",
    "        if ((row['AP_cha_cig']/row['AP_cig'] <= 0.5) or (row['AP_cha_cig'] == 1) or (row['AP_cha_cig'] <= row['possible_cig'])):\n",
    "            result.at[index, 'status cha'] = 'OK'\n",
    "        else:\n",
    "            result.at[index, 'status cha'] = 'no'\n",
    "    \n",
    "    if ((row['INDEX_ID'] == 1000328) and (row['bst'] == 4) and isinstance(row['cha'], str)):    \n",
    "        if ((row['AP_cha_beer']/row['AP_beer'] <= 0.5) or (row['AP_cha_beer'] == 1) or (row['AP_cha_beer'] <= row['possible_beer'])):\n",
    "            result.at[index, 'status cha'] = 'OK'\n",
    "        else:\n",
    "            result.at[index, 'status cha'] = 'no'\n",
    "            \n",
    "    if ((row['INDEX_ID'] == 1000328) and (row['bst'] == 501) and isinstance(row['cha'], str)):\n",
    "        result.at[index, 'status cha'] = result['status cha'][(result['outlet'] == row['outlet']) & (result['INDEX_ID'] == 1000334)].iloc[0]\n",
    "        \n",
    "    if (((row['INDEX_ID'] == 1000328) | (row['INDEX_ID'] == 1000334)) and (row['bst'] == 1) and isinstance(row['cha'], str)):\n",
    "        result.at[index, 'status cha'] = result['status cha'][(result['outlet'] == row['outlet']) & (result['INDEX_ID'] == 1000296)].iloc[0]\n",
    "\n",
    "#for index,row in result.iterrows():\n",
    "#    if (row['bst'] == 1 and isinstance(row['cha'], str) and (row['cell'] > 20000 and row['cell'] < 50000)): \n",
    "#        result.at[index, 'status cha'] = 'OK'\n",
    "#    if ((row['bst'] == 3 or row['bst'] == 501 or row['bst'] == 502) and isinstance(row['cha'], str) and (row['cell_c'] > 20000 and row['cell_c'] < 50000)): \n",
    "#        result.at[index, 'status cha'] = 'OK'\n",
    "#    if ((row['bst'] == 4 or row['bst'] == 501) and isinstance(row['cha'], str) and (row['cell_b'] > 20000 and row['cell_b'] < 50000)): \n",
    "#        result.at[index, 'status cha'] = 'OK'\n",
    "        \n",
    "writer = pd.ExcelWriter('main.xlsx')\n",
    "result.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[(result['AP_fmcg'] == 9999), 'AP_fmcg'] = 0\n",
    "result.loc[(result['AP_cig'] == 9999), 'AP_cig'] = 0\n",
    "result.loc[(result['AP_beer'] == 9999), 'AP_beer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "########вот здесь фулл документед инфо и другое смотреть проставляется не тот статус\n",
    "# fill column c_p\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'c_p'] = 0 \n",
    "    if (row['status_coca_pepsi'] == 'OK'):\n",
    "         result.at[index,'c_p'] = 1\n",
    "    if (row['status_coca_pepsi'] == 'No'):\n",
    "         result.at[index,'c_p'] = -1\n",
    "         \n",
    "# fill column baby\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'baby'] = 0 \n",
    "    if (row['status_baby'] == 'OK'):\n",
    "         result.at[index,'baby'] = 1\n",
    "    if (row['status_baby'] == 'No'):\n",
    "         result.at[index,'baby'] = -1\n",
    "         \n",
    "# fill column total\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'total'] = 0 \n",
    "    if (row['c_p'] + row['baby'] > 0):\n",
    "         result.at[index,'total'] = 1\n",
    "    if (row['c_p'] + row['baby'] < 0):\n",
    "         result.at[index,'total'] = -1        \n",
    "         \n",
    "# fill column final_status_microrep\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'final_status_microrep'] = 'neutral' \n",
    "    if (row['total'] > 0):\n",
    "         result.at[index,'final_status_microrep'] = 'OK'\n",
    "    if (row['total'] < 0):\n",
    "         result.at[index,'final_status_microrep'] = 'not'            \n",
    "         \n",
    "# fill column merge_data_quality         \n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'merge_data_quality'] = str(row['Interval for info']) + '-' + str(row['Source of info']) + '-' + str(row['Type of info']) \n",
    "             \n",
    "# fill column merge_panel_quality         \n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'merge_panel_quality'] = row['final_status_microrep'] \n",
    "\n",
    "# fill column data_quality\n",
    "for index,row in result.iterrows():\n",
    "    result.loc[index,'data_quality'] = 'wait' \n",
    "    if ((row['merge_data_quality'] == 'Full-documented-sales') or (row['merge_data_quality'] == 'Full-documented-purchase')):\n",
    "         result.loc[index,'data_quality'] = 'OK'\n",
    "\n",
    "# fill column panel_quality\n",
    "for index,row in result.iterrows():\n",
    "    result.loc[index,'panel_quality'] = 'OK' \n",
    "    if (row['final_status_microrep'] == 'not'):\n",
    "         result.loc[index,'panel_quality'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill final status\n",
    "result['final_status'] = result['status cha'] + '-' + result['data_quality'] + '-' + result['panel_quality']\n",
    "\n",
    "for index,row in result.iterrows():\n",
    "    result.at[index,'final_status_2'] = 'no' \n",
    "    if (row['final_status'] == 'OK-OK-OK'):\n",
    "         result.at[index,'final_status_2'] = 'OK'    \n",
    "    if (row['final_status'] == 'OK-wait-OK'):\n",
    "         result.at[index,'final_status_2'] = 'wait'       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# до этого шага один индекс = одна строка, после - одна тт = одна строка.\n",
    "final = pd.DataFrame(columns = ['outlet', 'pno', 'm1',\n",
    "                                #'region DA', \n",
    "                                'type', 'Type of info', 'Source of info',\n",
    "       'Interval for info', 'Comments for DA', 'bst', 'Outlet',\n",
    "       #'SMS_ID', 'STORE_TYPE', \n",
    "                                'TRADE_TYPE', 'PROVINCE', 'SALES_AREA',\n",
    "       'HL156', 'HL013', 'AUTORIZED', 'cha', \n",
    "                                #'SMS_SERVICE',\n",
    "                                'CITYCODE',\n",
    "       #'RU_REGION', 'RU_RGN', 'RU_CCN', 'NOT_NEED_CHA', 'NEED_CCODE', \n",
    "                                'RU_PGR',\n",
    "       #'RU_SUBJECT', 'RGN_BEER', 'CCN_BEER', 'REGION_CIG', 'RGN_CIG',\n",
    "       #'CCN_CIG', 'DIST_STRATA', 'RU_CHA', \n",
    "                                'cell_fmcg', 'cell_cig', 'cell_beer', 'status cha',\n",
    "       #'Chainact', \n",
    "                                'om', 'coca_check', 'pepsi_check', 'status_coca_pepsi',\n",
    "       'baby_f_check', 'baby_d_check', 'status_baby', \n",
    "        #                        'key_fmcg', 'key_cig', 'key_beer', \n",
    "        'Final Cell ID FMCG', 'Final Cell ID CIG', 'Final Cell ID BEER',\n",
    "        'universe fmcg', 'universe cig',\n",
    "       'universe beer', 'universe fmcg cha', 'universe cig cha',\n",
    "       'universe beer cha',\n",
    "        #                        'key_cha',\n",
    "        'AP_fmcg', 'AP_cig', 'AP_beer',\n",
    "                                \n",
    "       'AP_cha_fmcg', 'AP_cha_cig', 'AP_cha_beer',\n",
    "       'possible_fmcg', 'possible_cig', 'possible_beer', 'c_p', 'baby',\n",
    "       'total', 'final_status_microrep', 'merge_data_quality',\n",
    "       'merge_panel_quality', 'data_quality', 'panel_quality', 'final_status',\n",
    "       'final_status_2'])\n",
    "\n",
    "columns = ['outlet', 'pno', 'm1',\n",
    "           'type', 'Type of info', 'Source of info',\n",
    "       'Interval for info', 'Comments for DA', 'bst', 'Outlet',\n",
    "        'TRADE_TYPE', 'PROVINCE', 'SALES_AREA',\n",
    "       'HL156', 'HL013', 'AUTORIZED', 'cha', 'CITYCODE',\n",
    "       'RU_PGR',\n",
    "       #### 'cell_fmcg', 'cell_cig', 'cell_beer',\n",
    "       'status cha', 'om', 'coca_check', 'pepsi_check', 'status_coca_pepsi',\n",
    "       'baby_f_check', 'baby_d_check', 'status_baby', \n",
    "       #'key_cha',\n",
    "       #### 'key_fmcg', 'key_cig',       'key_beer', \n",
    "       #### 'Final Cell ID FMCG', 'Final Cell ID CIG', 'Final Cell ID BEER',\n",
    "       #'universe fmcg', 'universe cig',\n",
    "       #'universe beer', 'universe fmcg cha', 'universe cig cha',\n",
    "       #'universe beer cha', 'AP_fmcg', 'AP_cig', 'AP_beer', 'AP_cha_fmcg', 'AP_cha_cig', 'AP_cha_beer',\n",
    "       #'possible_fmcg', 'possible_cig', 'possible_beer',\n",
    "       'c_p', 'baby',\n",
    "       'total', 'final_status_microrep', 'merge_data_quality',\n",
    "       'merge_panel_quality', 'data_quality', 'panel_quality', 'final_status',\n",
    "       'final_status_2']\n",
    "\n",
    "# здесть те колонки, что в предыдущем списке стоят после решетки (суммируем значения в колнке для одной и той же тт)\n",
    "shmolumns = ['universe fmcg', 'universe cig', 'universe beer', 'universe fmcg cha', 'universe cig cha',\n",
    "             'universe beer cha', 'AP_fmcg', 'AP_cig', 'AP_beer',\n",
    "             'AP_cha_fmcg', 'AP_cha_cig', 'AP_cha_beer',\n",
    "             'possible_fmcg', 'possible_cig', 'possible_beer']\n",
    "\n",
    "l = -1\n",
    "for k in result['outlet'].unique():\n",
    "    l += 1\n",
    "    for m in columns:\n",
    "        try:\n",
    "            final.loc[l, m] = result[result['outlet'] == k][m].unique().item()\n",
    "        except:\n",
    "            print(m, k, 'для одной и той же тт в разных индексах стоят разные значения параметра, которые должны быть одинаковыми')\n",
    "    for n in shmolumns:\n",
    "        final.loc[l, n] = result[result['outlet'] == k][n].sum()\n",
    "    # здесь обрабатываются колонки, помеченные четырьмя решетками\n",
    "    for i, j in result[result['outlet'] == k].iterrows():\n",
    "        if j['INDEX_ID'] == 1000296:\n",
    "            final.loc[l, 'cell_fmcg'] = j['cell']\n",
    "            #final.loc[l, 'key_fmcg'] = j['key_fmcg']\n",
    "            final.loc[l, 'Final Cell ID FMCG'] = j['Final Cell ID']\n",
    "        if j['INDEX_ID'] == 1000334:\n",
    "            final.loc[l, 'cell_cig'] = j['cell']\n",
    "            #final.loc[l, 'key_cig'] = j['key_cig']\n",
    "            final.loc[l, 'Final Cell ID CIG'] = j['Final Cell ID']\n",
    "        if j['INDEX_ID'] == 1000328:\n",
    "            final.loc[l, 'cell_beer'] = j['cell']\n",
    "            #final.loc[l, 'key_beer'] = j['key_beer']\n",
    "            final.loc[l, 'Final Cell ID BEER'] = j['Final Cell ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tracking system with all checks (except for cha)\n",
    "writer = pd.ExcelWriter('main.xlsx')\n",
    "final.to_excel(writer, 'Sheet1', index = False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
